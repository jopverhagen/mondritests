{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54628662-5403-4b36-adb9-abfad05f4d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████████████████████████████████████████████████████████████████| 270/270 [00:37<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Gemiddelde loss = 0.273607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████████████████████████████████████████████████████████████████| 270/270 [00:37<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Gemiddelde loss = 0.081430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████████████████████████████████████████████████████████████████| 270/270 [00:37<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Gemiddelde loss = 0.065651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████████████████████████████████████████████████████████████████| 270/270 [00:37<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Gemiddelde loss = 0.050542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████████████████████████████████████████████████████████████████| 270/270 [00:37<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Gemiddelde loss = 0.047046\n",
      "Test sample 0 opgeslagen.\n",
      "Test sample 1 opgeslagen.\n",
      "Test sample 2 opgeslagen.\n",
      "Test sample 3 opgeslagen.\n",
      "Test sample 4 opgeslagen.\n",
      "Test sample 5 opgeslagen.\n",
      "Test sample 6 opgeslagen.\n",
      "Test sample 7 opgeslagen.\n",
      "Test sample 8 opgeslagen.\n",
      "Test sample 9 opgeslagen.\n",
      "Test sample 10 opgeslagen.\n",
      "Test sample 11 opgeslagen.\n",
      "Test sample 12 opgeslagen.\n",
      "Test sample 13 opgeslagen.\n",
      "Test sample 14 opgeslagen.\n",
      "Test sample 15 opgeslagen.\n",
      "Test sample 16 opgeslagen.\n",
      "Test sample 17 opgeslagen.\n",
      "Test sample 18 opgeslagen.\n",
      "Test sample 19 opgeslagen.\n",
      "Test sample 20 opgeslagen.\n",
      "Test sample 21 opgeslagen.\n",
      "Test sample 22 opgeslagen.\n",
      "Test sample 23 opgeslagen.\n",
      "Test sample 24 opgeslagen.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# --- Utility modules ---\n",
    "\n",
    "# Residual Block met skip-verbinding (1x1 convolution indien nodig)\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # Indien in_channels != out_channels, pas dan een 1x1 convolution toe op de skip-verbinding.\n",
    "        if in_channels != out_channels:\n",
    "            self.skip_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        else:\n",
    "            self.skip_conv = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        if self.skip_conv is not None:\n",
    "            identity = self.skip_conv(identity)\n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "# Downsample laag (conv met stride 2)\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Downsample, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))\n",
    "\n",
    "# Upsample laag (transposed conv)\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))\n",
    "\n",
    "# --- UNet Generator ---\n",
    "\n",
    "# De UNet is hier aangepast zodat deze conditionele informatie kan verwerken. \n",
    "# De input bestaat uit de concatenatie van:\n",
    "# - een \"noisy\" high quality–afbeelding (die met DDPM-ruis is aangetast)\n",
    "# - de low quality–afbeelding als condition\n",
    "# Daardoor krijgt de UNet 6 kanalen als input en voorspelt zij de ruis (3 kanalen) die moet worden verwijderd.\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, base_channels=64):\n",
    "        super(UNet, self).__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = ResidualBlock(in_channels, base_channels)           # in_channels = 6 (3 noisy + 3 condition)\n",
    "        self.down1 = Downsample(base_channels, base_channels * 2)         # 64 -> 128\n",
    "        self.enc2 = ResidualBlock(base_channels * 2, base_channels * 2)     # 128 -> 128\n",
    "        self.down2 = Downsample(base_channels * 2, base_channels * 4)       # 128 -> 256\n",
    "        self.enc3 = ResidualBlock(base_channels * 4, base_channels * 4)     # 256 -> 256\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResidualBlock(base_channels * 4, base_channels * 4) # 256 -> 256\n",
    "\n",
    "        # Decoder\n",
    "        self.up2 = Upsample(base_channels * 4, base_channels * 2)           # 256 -> 128\n",
    "        self.dec2 = ResidualBlock(base_channels * 4, base_channels * 2)       # na concat: 128+128=256 -> 128\n",
    "        self.up1 = Upsample(base_channels * 2, base_channels)               # 128 -> 64\n",
    "        self.dec1 = ResidualBlock(base_channels * 2, base_channels)           # na concat: 64+64=128 -> 64\n",
    "\n",
    "        # Output: voorspelt 3 kanalen (ruis)\n",
    "        self.output_conv = nn.Conv2d(base_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x, time_embedding=None):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(self.down1(enc1))\n",
    "        enc3 = self.enc3(self.down2(enc2))\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(enc3)\n",
    "        # Decoder\n",
    "        up2 = self.up2(bottleneck)\n",
    "        dec2 = self.dec2(torch.cat([up2, enc2], dim=1))\n",
    "        up1 = self.up1(dec2)\n",
    "        dec1 = self.dec1(torch.cat([up1, enc1], dim=1))\n",
    "        return self.output_conv(dec1)\n",
    "\n",
    "# --- DDPM Noise Scheduler en Sampler ---\n",
    "\n",
    "# Deze klasse beheert het toevoegen van ruis en het omkeren van het diffusieproces.\n",
    "class DDPM(nn.Module):\n",
    "    def __init__(self, model, timesteps=1000, beta_start=1e-4, beta_end=0.02, device=\"cuda\"):\n",
    "        super(DDPM, self).__init__()\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = model.to(self.device)\n",
    "        self.timesteps = timesteps\n",
    "        self.betas = torch.linspace(beta_start, beta_end, timesteps, device=self.device)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alpha_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.alphas = self.alphas.to(self.device)\n",
    "        self.alpha_cumprod = self.alpha_cumprod.to(self.device)\n",
    "        \n",
    "    def add_noise(self, x, t):\n",
    "        \"\"\"\n",
    "        Voeg ruis toe aan x volgens het DDPM schema op timestep t.\n",
    "        x: clean (high quality) image, t: tensor met timesteps per sample.\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(x)\n",
    "        # t heeft vorm (batch,); haal voor elke sample de juiste cumulatieve alpha op.\n",
    "        sqrt_alpha_cumprod = torch.sqrt(self.alpha_cumprod[t]).view(-1, 1, 1, 1)\n",
    "        sqrt_one_minus_alpha_cumprod = torch.sqrt(1 - self.alpha_cumprod[t]).view(-1, 1, 1, 1)\n",
    "        noisy = sqrt_alpha_cumprod * x + sqrt_one_minus_alpha_cumprod * noise\n",
    "        return noisy, noise\n",
    "\n",
    "    def forward(self, x, cond, t):\n",
    "        \"\"\"\n",
    "        Forward pass tijdens training: voorspel de toegevoegde ruis.\n",
    "        x: noisy image (afgeleid van de high quality image)\n",
    "        cond: condition (low quality image)\n",
    "        t: timestep (per sample)\n",
    "        \"\"\"\n",
    "        # Concateneer noisy image en condition langs de channel-dimensie.\n",
    "        x_in = torch.cat([x, cond], dim=1)\n",
    "        return self.model(x_in, t)\n",
    "\n",
    "    def p_sample(self, x, t, cond):\n",
    "        \"\"\"\n",
    "        Voer één reverse diffusion stap uit.\n",
    "        x: huidige x_t (batch van afbeeldingen)\n",
    "        t: huidige timestep (gehele getal)\n",
    "        cond: condition (low quality image)\n",
    "        \"\"\"\n",
    "        # Maak een tensor van t met de batchgrootte\n",
    "        t_tensor = torch.tensor([t], device=self.device).long().expand(x.size(0))\n",
    "        model_out = self.model(torch.cat([x, cond], dim=1), t_tensor)\n",
    "        alpha_cumprod_t = self.alpha_cumprod[t]\n",
    "        sqrt_recip_alpha_t = 1.0 / torch.sqrt(self.alphas[t])\n",
    "        sqrt_one_minus_alpha_cumprod_t = torch.sqrt(1 - alpha_cumprod_t)\n",
    "        # Bereken voorspelling van de clean image x0\n",
    "        x0_pred = (x - sqrt_one_minus_alpha_cumprod_t * model_out) * sqrt_recip_alpha_t\n",
    "        if t == 0:\n",
    "            return x0_pred\n",
    "        beta_t = self.betas[t]\n",
    "        alpha_cumprod_prev = self.alpha_cumprod[t-1]\n",
    "        # Bereken de posterior variantie volgens het DDPM-schema\n",
    "        posterior_variance = beta_t * (1 - alpha_cumprod_prev) / (1 - alpha_cumprod_t)\n",
    "        noise = torch.randn_like(x)\n",
    "        mean = torch.sqrt(alpha_cumprod_prev) * x0_pred\n",
    "        x_prev = mean + torch.sqrt(posterior_variance) * noise\n",
    "        return x_prev\n",
    "\n",
    "    def sample(self, cond):\n",
    "        \"\"\"\n",
    "        Voer het volledige reverse diffusieproces uit om een herstelde afbeelding (x0) te genereren,\n",
    "        gegeven de condition (low quality image).\n",
    "        \"\"\"\n",
    "        # Begin met pure ruis (vorm: (batch, 3, H, W))\n",
    "        x = torch.randn_like(cond).to(self.device)\n",
    "        for t in reversed(range(1, self.timesteps)):\n",
    "            x = self.p_sample(x, t, cond)\n",
    "        # Laatste stap bij t = 0\n",
    "        t0 = 0\n",
    "        t_tensor = torch.tensor([t0], device=self.device).long().expand(x.size(0))\n",
    "        model_out = self.model(torch.cat([x, cond], dim=1), t_tensor)\n",
    "        sqrt_recip_alpha0 = 1.0 / torch.sqrt(self.alphas[t0])\n",
    "        sqrt_one_minus_alpha_cumprod0 = torch.sqrt(1 - self.alpha_cumprod[t0])\n",
    "        x0_pred = (x - sqrt_one_minus_alpha_cumprod0 * model_out) * sqrt_recip_alpha0\n",
    "        return x0_pred\n",
    "\n",
    "# --- Dataset ---\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, lq_dir, hq_dir, transform=None):\n",
    "        self.lq_paths = sorted([os.path.join(lq_dir, f) for f in os.listdir(lq_dir) \n",
    "                                  if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
    "        self.hq_paths = sorted([os.path.join(hq_dir, f) for f in os.listdir(hq_dir) \n",
    "                                  if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
    "        if len(self.lq_paths) == 0 or len(self.hq_paths) == 0:\n",
    "            raise ValueError(f\"Dataset is leeg! Controleer paden: {lq_dir} en {hq_dir}\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lq_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        lq_image = self._load_image(self.lq_paths[index])\n",
    "        hq_image = self._load_image(self.hq_paths[index])\n",
    "        if self.transform:\n",
    "            lq_image = self.transform(lq_image)\n",
    "            hq_image = self.transform(hq_image)\n",
    "        return lq_image, hq_image\n",
    "\n",
    "    def _load_image(self, path):\n",
    "        return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "# --- Training en Test Framework ---\n",
    "\n",
    "class ImageRestorationModel:\n",
    "    def __init__(self, lq_dir, hq_dir, test_lq_dir, test_hq_dir, device=\"cuda\"):\n",
    "        self.device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "        # Let op: de UNet krijgt 6 inputkanalen (noisy + condition) en voorspelt 3 outputkanalen (ruis)\n",
    "        self.model = UNet(in_channels=6, out_channels=3).to(self.device)\n",
    "        self.ddpm = DDPM(self.model, timesteps=1000, device=device).to(self.device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.train_dataset = ImageDataset(lq_dir, hq_dir, transform=transform)\n",
    "        self.test_dataset = ImageDataset(test_lq_dir, test_hq_dir, transform=transform)\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=8, shuffle=True)\n",
    "        self.test_loader = DataLoader(self.test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    def train(self, epochs=10):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for lq, hq in tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "                lq, hq = lq.to(self.device), hq.to(self.device)\n",
    "                # Kies voor elke sample een willekeurige timestep t\n",
    "                t = torch.randint(0, self.ddpm.timesteps, (lq.size(0),), device=self.device)\n",
    "                # Voeg ruis toe aan de high quality image\n",
    "                noisy_hq, noise = self.ddpm.add_noise(hq, t)\n",
    "                # Geef de noisy image samen met de low quality image (condition) aan het model\n",
    "                pred_noise = self.ddpm(noisy_hq, lq, t)\n",
    "                loss = self.criterion(pred_noise, noise)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            print(f\"Epoch {epoch+1}: Gemiddelde loss = {epoch_loss/len(self.train_loader):.6f}\")\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (lq, hq) in enumerate(self.test_loader):\n",
    "                lq = lq.to(self.device)\n",
    "                # Genereer de herstelde afbeelding via reverse diffusion\n",
    "                restored = self.ddpm.sample(lq)\n",
    "                save_image(restored, f\"restored_{idx}.png\")\n",
    "                save_image(hq.to(self.device), f\"ground_truth_{idx}.png\")\n",
    "                print(f\"Test sample {idx} opgeslagen.\")\n",
    "\n",
    "# --- Main ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Stel de paden in voor de Low Quality (LQ) en High Quality (HQ) afbeeldingen\n",
    "    lq_dir = \"data/train/low\"\n",
    "    hq_dir = \"data/train/high\"\n",
    "    test_lq_dir = \"data/test/low\"\n",
    "    test_hq_dir = \"data/test/high\"\n",
    "\n",
    "    # Initialiseer en train het model\n",
    "    model = ImageRestorationModel(lq_dir, hq_dir, test_lq_dir, test_hq_dir, device=\"cuda\")\n",
    "    model.train(epochs=5)\n",
    "\n",
    "    # Test het model\n",
    "    model.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3784a2e7-1397-4b3d-8160-b688a9569f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/low contains 2160 files\n",
      "data/train/high contains 2160 files\n",
      "data/test/low contains 25 files\n",
      "data/test/high contains 25 files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "lq_dir = \"data/train/low\"\n",
    "hq_dir = \"data/train/high\"\n",
    "\n",
    "test_lq_dir = \"data/test/low\"\n",
    "test_hq_dir = \"data/test/high\"\n",
    "\n",
    "# Check if directories exist\n",
    "for path in [lq_dir, hq_dir, test_lq_dir, test_hq_dir]:\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Directory does not exist: {path}\")\n",
    "    else:\n",
    "        print(f\"{path} contains {len(os.listdir(path))} files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003644a4-95d2-4934-8da9-b542bbd6b6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
